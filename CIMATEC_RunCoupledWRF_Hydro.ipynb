{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNHsAnBEL5zfMrPUePMOTX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertodantas/CIMATEC_WRF-Hydro/blob/robertodantas.github.io/CIMATEC_RunCoupledWRF_Hydro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Lesson - Running the coupled WRF | WRF-Hydro modeling system\n",
        "Overview\n",
        "\n",
        "In this lesson we cover the basics of how to run a coupled WRF | WRF-Hydro simulation using a prepared domain from the provided coupled test case. In particular, we cover how to run the necessary WRF Preprocessing System (WPS) utitilies and the coupled modeling system itself.\n",
        "\n",
        "For more information regarding the WRF and WRF-Hydro modeling systems please consult the relevant documentation.\n",
        "Software and conventions\n",
        "\n",
        "The easiest way to run this lesson is via the wrfhydro/coupled_training Docker container, which has the pre-compiled modeling system and required WPS geographic data installed.\n",
        "\n",
        "You may either execute commands by running each cell of this notebook or alternatively you may open a terminal in Jupyter Lab by selecting New -> Terminal in your Home tab of Jupyter Lab and input the commands manually if you prefer. You can also use your own terminal by logging into the container with the command docker exec -it wrf-hydro-coupled-training bash\n",
        "\n",
        "All paths used in this lesson assume that the lesson materials are located under your home directory in a folder named wrf-hydro-training. If your materials are located in another directory, you will not be able to run the commands in this notebook inside Jupyter and will need to type them manually in your terminal session.\n",
        "Container contents\n",
        "\n",
        "The wrfhydro/coupled_training Docker container developed for this lesson contains the following:\n",
        "\n",
        "    The precompiled WRF Preprocessing System (WPS) and required data\n",
        "    The precompiled coupled WRF | WRF-Hydro modeling system\n",
        "    A coupled test case compatible with the specified version\n",
        "    Training lesson as a Jupyter Notebook\n",
        "    Jupyter Notebook server\n",
        "\n",
        "Lesson contents\n",
        "\n",
        "This lesson walks through the process of running both the WRF Preprocessing system (WPS) to generate necessary input files and the coupled WRF | WRF-Hydro model.\n",
        "\n",
        "In order to run the WPS there are effectively three main steps:\n",
        "\n",
        "    Define a model domain and any nested domains with geogrid.\n",
        "\n",
        "    Extract meteorological fields from GRIB data sets for the simulation period with ungrib.\n",
        "\n",
        "    Horizontally interpolate meteorological fields to the model domains with metgrid.\n",
        "\n",
        "From here we use prepared WRF-Hydro input files from the coupled test case and the files generated via the WPS utilities to run real, a utility to produce intial and boundary condition files for the WRF simulation, and finally the coupled model itself.\n",
        "Running the WRF Preprocessing System (WPS)\n",
        "\n",
        "We will start the lesson by running the WRF Preprocessing System (WPS) utilities.\n",
        "\n",
        "WPS consists of a set of utilities developed to aid users in model domain generation and formatting/processing of relevant input datasets for both the land and atmosphere.\n",
        "\n",
        "The three primary utilities included in the WPS are geogrid, ungrib, and metgrid. The following sections briefly describe each of these utilities step through the process of running each of them.\n",
        "Running the geogrid utility\n",
        "\n",
        "The first of the WPS utilities is geogrid. The geogrid utility creates geogrid domain files from geospatial data (distributed by the WRF developers) based upon model domain parameters specified in the geogrid portion of the namelist.wps file as well as interpolation options specified in the GEOGRID.TBL file (distributed with WPS).\n",
        "\n",
        "Before running the utility we need to create and populate our run directory as shown below."
      ],
      "metadata": {
        "id": "mVDL2PwyYaQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a run directory for WPS and navigate there\n",
        "mkdir -p ~/wrf-hydro-training/output/run/WPS\n",
        "cd ~/wrf-hydro-training/output/run/WPS\n",
        "\n",
        "# Link the required geospatial data to the proper folder\n",
        "# Note that only a subset of the full dataset is included in this container\n",
        "ln -sf ~/WRF_WPS/geog_conus geog\n",
        "\n",
        "# Link the precompiled executable\n",
        "ln -sf ~/WRF_WPS/WPS/geogrid.exe .\n",
        "\n",
        "# Copy over the required geogrid parameter table from the WPS/geogrid directory\n",
        "cp ~/WRF_WPS/WPS/geogrid/GEOGRID.TBL .\n",
        "\n",
        "# Copy over the preconfigured WPS namelist from the example case\n",
        "cp ~/wrf-hydro-training/example_case_coupled/namelist.wps ."
      ],
      "metadata": {
        "id": "mk8ggPlmYe5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will take a look at the WPS namelist. Recall from above that the relevant portion of the namelist for this utility is called geogrid."
      ],
      "metadata": {
        "id": "UkIIwo5aYk_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat namelist.wps"
      ],
      "metadata": {
        "id": "WQRq2wurYpoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now we will go ahead and run the geogrid utility and view the output log file."
      ],
      "metadata": {
        "id": "IVq6hmouYsFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the geogrid utility and pipe the output to a log file\n",
        "./geogrid.exe > geogrid.log 2>&1\n",
        "\n",
        "# View the log file to check for successful completion\n",
        "cat geogrid.log\n"
      ],
      "metadata": {
        "id": "118wxaRlY3FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Running the ungrib utility\n",
        "\n",
        "The next WPS utility is ungrib. The ungrib utility takes meteorological forcing data (included in the example case) to be used for simulation initial and boundary conditions and converts the files to an intermediate file format used by the metgrid utility.\n",
        "\n",
        "Again, we first populate the run directory with the required input files.\n"
      ],
      "metadata": {
        "id": "50GpRRQOY51i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Link the required shell script and precompiled executable from WPS\n",
        "ln -sf ~/WRF_WPS/WPS/link_grib.csh .\n",
        "ln -sf ~/WRF_WPS/WPS/ungrib.exe ."
      ],
      "metadata": {
        "id": "k228DaBmY-vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we link the meteorological forcing data from the example case using the provided shell script. This script links the files to the run directory and renames them appropriately.\n",
        "\n",
        "We also link the relevant variable table (NAM in this case) provided with WPS at this point."
      ],
      "metadata": {
        "id": "frJKjqcMZPtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Link the example case meteorological forcing data with the provided shell script\n",
        "./link_grib.csh ~/wrf-hydro-training/example_case_coupled/WRF_FORCING/*\n",
        "\n",
        "# Link the relevant variable table for the meteorological forcing data we are using\n",
        "ln -sf ~/WRF_WPS/WPS/ungrib/Variable_Tables/Vtable.NAM Vtable"
      ],
      "metadata": {
        "id": "zXON2CCWZQmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to run the ungrib utility as shown below. Recall that there is also an ungrib section in the namelist.wps. Again, these are preconfigured for your example case."
      ],
      "metadata": {
        "id": "HKOzrZEcZVQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the ungrib utility and pipe the output to a log file\n",
        "./ungrib.exe > ungrib.log 2>&1\n",
        "\n",
        "# View the last few lines of the log file to check for successful completion\n",
        "tail ungrib.log"
      ],
      "metadata": {
        "id": "JFB9NqtVZZch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Running the metgrid utility\n",
        "\n",
        "Finally, we will run the metgrid utility. The metgrid utility does some interpolation of meteorological forcing data to the model domain creating metgrid files to be used as input to the WRF real utility.\n",
        "\n",
        "Once again, our first step is to populate the run directory with the required input files.\n"
      ],
      "metadata": {
        "id": "zVQdPNWkZdEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy over the required geogrid parameter table from the WPS/geogrid directory\n",
        "cp ~/WRF_WPS/WPS/metgrid/METGRID.TBL .\n",
        "\n",
        "# Link the relevant executable\n",
        "ln -sf ~/WRF_WPS/WPS/metgrid.exe .\n"
      ],
      "metadata": {
        "id": "V_0n8AycZgi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to run the metgrid utility as shown below. Recall that there is also a metgrid section in the namelist.wps. Again, these are preconfigured for your example case."
      ],
      "metadata": {
        "id": "4anhInXxZlcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the metgrid utility and pipe the output to a log file\n",
        "./metgrid.exe > metgrid.log 2>&1\n",
        "\n",
        "# View the last few lines of the log file to check for successful completion\n",
        "cat metgrid.log"
      ],
      "metadata": {
        "id": "ybxd77jWZoAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Running the coupled WRF | WRF-Hydro modeling system\n",
        "\n",
        "Now that we have generated the geogrid and metgrid files for the model domains using the WPS utilities we are ready to start the process of running the coupled modeling system.\n",
        "\n",
        "Note that at this point in a real simulation (over a domain of your choice) you would need to take the geogrid file from the innermost domain and run the WRF-Hydro GIS preprocessing tools to generate your hydro domain files. In this example case, all of the required files are generated for you and included in the DOMAIN directory within the example case.\n",
        "\n",
        "Setting up your run directory\n",
        "\n",
        "First, we will go ahead and setup the run directory for the coupled model simulation as shown below.\n",
        "\n"
      ],
      "metadata": {
        "id": "R9WdppiPZqd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the run directory from the precompiled WRF directory (this was compiled with hydro)\n",
        "cp -RL ~/WRF_WPS/WRF/run ~/wrf-hydro-training/output/run/WRF\n",
        "\n",
        "# Navigate to the new run directory\n",
        "cd ~/wrf-hydro-training/output/run/WRF\n",
        "\n",
        "# Copy over required parameter tables for the hydro components\n",
        "cp ~/WRF_WPS/wrf_hydro_nwm_public*/trunk/NDHMS/template/HYDRO/*TBL .\n",
        "\n",
        "# Copy over the namelist used for real and WRF as well as the hydro\n",
        "# namelist from the example case directory\n",
        "cp ~/wrf-hydro-training/example_case_coupled/namelist.input .\n",
        "cp ~/wrf-hydro-training/example_case_coupled/hydro.namelist .\n",
        "\n",
        "# Link the relevant executables\n",
        "cp ~/WRF_WPS/WRF/run/wrf.exe .\n",
        "cp ~/WRF_WPS/WRF/run/real.exe .\n",
        "\n",
        "# Link the geogrid and metgrid files you just created using the WPS\n",
        "ln -sf ../WPS/geo_em* .\n",
        "ln -sf ../WPS/met_em* .\n",
        "\n",
        "# Link the hydro domain files from the coupled example case directory\n",
        "ln -sf ~/wrf-hydro-training/example_case_coupled/DOMAIN ."
      ],
      "metadata": {
        "id": "g-AchR6bZ2sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Running real\n",
        "\n",
        "Next we will run real. This utility is used for real data (as opposed to idealized) WRF simulations and uses the geogrid and metgrid files as input. Based upon these input files and specifications in the namelist.input real.exe generates the initial (wrfinput) and boundary (wrfbdy) condition files required for the simulation.\n"
      ],
      "metadata": {
        "id": "4uTjJHSrZ6Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the real utility and pipe the output to a log file\n",
        "# Note that this binary was compiled using distributed memory parallelism (thus the -np 2)\n",
        "# if you are running on your own system the run command may be different\n",
        "mpirun -np 2 ./real.exe > real.log 2>&1\n"
      ],
      "metadata": {
        "id": "MgnhlJkgZ9NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "View the end of your log file to ensure the simulation completed\n",
        "\n",
        "Depending upon how you run the real and wrf utilities, a number of log files are created. In this case there is one standard out (rsl.out.) and one standard error (rsl.error.) file for each processor. We recommend looking for the successful completion statement at the end of the rsl.out.* files as shown below and checking for any errors within these log files. For additional output from WRF and WRF-Hydro compile time diagnostic flags can be set to aid in troubleshooting. See the relevant documentation for information regarding these options.\n"
      ],
      "metadata": {
        "id": "ocE84pDZaALK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the last few lines of the log file to check for successful completion\n",
        "tail rsl.out.0000"
      ],
      "metadata": {
        "id": "s7EVm1jOaEax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Running the coupled model\n",
        "\n",
        "Now we are ready to run the coupled WRF | WRF-Hydro simulation. Note that WRF-Hydro has been compiled as a library referenced by WRF and therefore we can just run a single wrf.exe executable. Namelist options are specified in namelist.input for the WRF model (options typically set in the namelist.hrldas for standalone WRF-Hydro simulations can also be found in here) and hydro.namelist for hydro components.\n"
      ],
      "metadata": {
        "id": "CQLnZKiGaG8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the coupled WRF|WRF-Hydro model via the wrf.exe executable and pipe the output to a log file\n",
        "# Note that this binary was compiled using distributed memory parallelism (thus the -np 2)\n",
        "# if you are running on your own system the run command may be different\n",
        "mpirun -np 2 ./wrf.exe > wrf.log 2>&1\n",
        "\n"
      ],
      "metadata": {
        "id": "UAmPwWFFaJ_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "View the end of your log file to ensure the simulation completed\n"
      ],
      "metadata": {
        "id": "Q0Io0AChaMu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the last few lines of the log file to check for successful completion\n",
        "tail rsl.out.0000"
      ],
      "metadata": {
        "id": "S1E9P_2taPJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now list the files in your run directory\n",
        "\n",
        "You should notice a number of familiar WRF-Hydro output files as well as some WRF output (wrfout*) files. Note that fields typically found in LDASOUT files for a standalone WRF-Hydro simulation can be found in these WRF output files.\n"
      ],
      "metadata": {
        "id": "wL3EAq8baSKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List the files\n",
        "ls\n"
      ],
      "metadata": {
        "id": "t7e8MB3uaU_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Viewing your model output\n",
        "\n",
        "All of the output data from this WRF | WRF-Hydro simulation are stored in netCDF files. Note that there are a number of utilites available for viewing and manipulating data in this format (e.g. ncview, NCO, Panoply) and packages available for reading these files using common languages for data analysis (e.g. R, Python, NCL).\n",
        "\n",
        "Here we will take a look at several of the output files using a couple of useful open source Python packages.\n",
        "\n",
        "Import the required Python modules\n",
        "\n",
        "First we import the required Python modules for this section. These include xarray, a Python package for data analysis with labeled arrays, and pyplot from matplotlib, a commonly used Python plotting package.\n"
      ],
      "metadata": {
        "id": "ONv-3czfaX5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "metadata": {
        "id": "xcAVWqT2abqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Open your dataset\n",
        "\n",
        "Next we open a multifile dataset consisting of our gridded channel output files using xarray. You will note that rather than explicitly specifying all of the filepaths we can use a wildcard to grab files for all dates.\n",
        "\n"
      ],
      "metadata": {
        "id": "uGxmF_W0aeU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = xr.open_mfdataset('/home/docker/wrf-hydro-training/output/run/WRF/*.CHRTOUT_GRID2', combine='by_coords')"
      ],
      "metadata": {
        "id": "5h4TwkGuahN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Plot your data\n",
        "\n",
        "Now we will plot the streamflow data as faceted grids (one for each output time step). While we do not see a large response, you can see some streamflow particularly in the upper right portion of the domain.\n"
      ],
      "metadata": {
        "id": "AoMwkZUcanEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.streamflow[1:].plot(col='time', col_wrap=2, vmin=0, aspect=ds.x.size/ds.y.size)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RQgCtIuQaoHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This concludes the lesson.\n",
        "\n",
        "Next visualize some of the outputs from this simulation in the following lesson."
      ],
      "metadata": {
        "id": "_ZKZmiiEaqb3"
      }
    }
  ]
}